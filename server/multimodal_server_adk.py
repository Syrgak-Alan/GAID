import asyncio
import base64
import contextlib
import json
import logging
import os
import re
import tempfile
import threading
import time

from dotenv import load_dotenv
from websockets.exceptions import ConnectionClosed, ConnectionClosedError

# Google ADK
from google.adk.agents import Agent, LiveRequestQueue
from google.adk.agents.run_config import RunConfig, StreamingMode
from google.adk.runners import Runner
from google.adk.sessions.in_memory_session_service import InMemorySessionService
from google.genai import types

# –í–∞—à–∏ –º–æ–¥—É–ª–∏
from backend.gAIde.story_teller.generate_story_func import generate_story_sync
from backend.gAIde.story_teller.config import USER_PROFILE
from common import (
    BaseWebSocketServer,
    logger,
    MODEL,
    VOICE_NAME,
    SEND_SAMPLE_RATE,
    SYSTEM_INSTRUCTION,  # <-- –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç –∏–∑ –ø—Ä–æ—à–ª–æ–π —á–∞—Å—Ç–∏
)

load_dotenv()


class MultimodalADKServer(BaseWebSocketServer):
    """WebSocket server implementation for multimodal input (audio + video) using Google ADK."""

    def __init__(self, host: str = "0.0.0.0", port: int = 8765):
        super().__init__(host, port)

        # –°–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∫–∞–¥—Ä–∞ + –∑–∞—â–∏—Ç–∞ –ø–æ—Ç–æ–∫–∞
        self.latest_frame: bytes | None = None
        self.latest_frame_ts: float = 0.0
        self._frame_lock = threading.Lock()

        # –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –≤—ã–∑–æ–≤ describe_place –≤ —Ç–µ–∫—É—â–µ–º —Ö–æ–¥–µ
        self._allow_describe_place: bool = False

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞ —Å –ø—Ä–∏–≤—è–∑–∞–Ω–Ω—ã–º –º–µ—Ç–æ–¥–æ–º-–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–º
        self.agent = Agent(
            name="customer_service_agent",
            model=MODEL,
            instruction=SYSTEM_INSTRUCTION,
            tools=[self.describe_place],  # –í–ê–ñ–ù–û: bound-–º–µ—Ç–æ–¥
        )

        self.session_service = InMemorySessionService()

    # ---------- SERVER-SIDE INTENT CHECK ----------

    @staticmethod
    def _allow_from_user_text(text: str) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –ø—Ä–æ—Å–∏–ª –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–ø—É—Å—Ç–∏—Ç—å/–≤—ã–ø–æ–ª–Ω–∏—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ –º–µ—Å—Ç–∞."""
        t = text.lower()
        patterns = [
            r"\brun\s+describe_place\b",
            r"\bdescribe\s+(this|the)?\s*(place|building|landmark)\b",
            r"\bwhat\s+is\s+this\s+(place|building|landmark)\b",
            # —Ä—É—Å—Å–∫–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã (–ø–æ –∂–µ–ª–∞–Ω–∏—é):
            r"\b–∑–∞–ø—É—Å—Ç–∏\s+describe_place\b",
            r"\b–æ–ø–∏—à–∏\s+(—ç—Ç–æ|–∑–¥–∞–Ω–∏–µ|–º–µ—Å—Ç–æ|–¥–æ—Å—Ç–æ–ø—Ä–∏–º–µ—á–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å)\b",
        ]
        return any(re.search(p, t) for p in patterns)

    # ---------- TOOL (—Å –∂—ë—Å—Ç–∫–∏–º –≥–µ–π—Ç–æ–º) ----------

    def describe_place(self) -> str:
        """
        –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–æ—Å—Ç—É–ø–µ–Ω –¢–û–õ–¨–ö–û –µ—Å–ª–∏:
        1) –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —è–≤–Ω–æ –ø–æ–ø—Ä–æ—Å–∏–ª (server-side —Ñ–ª–∞–≥ True)
        2) –ï—Å—Ç—å —Å–≤–µ–∂–∏–π –∫–∞–¥—Ä (–Ω–∞–ø—Ä–∏–º–µ—Ä, –Ω–µ —Å—Ç–∞—Ä—à–µ 3 —Å–µ–∫)
        """
        # 1) –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏—è (—Ñ–ª–∞–≥ –≤—ã—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–µ–∫—Å—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)
        if not self._allow_describe_place:
            return (
                "I‚Äôm ready to describe a place when you ask. "
                "Say: 'Describe this place' or 'Run describe_place'."
            )

        # 2) –°–≤–µ–∂–µ—Å—Ç—å –∫–∞–¥—Ä–∞
        with self._frame_lock:
            frame = self.latest_frame
            ts = self.latest_frame_ts

        if not frame or (time.time() - ts) > 3.0:
            return (
                "I don‚Äôt have a fresh camera frame yet. "
                "Please show the place to the camera or send an image."
            )

        # 3) –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –ø–æ –∫–∞–¥—Ä—É
        tmp_path = None
        try:
            with tempfile.NamedTemporaryFile(suffix=".jpg", delete=False) as tmp:
                tmp.write(frame)
                tmp_path = tmp.name

            story = generate_story_sync(tmp_path, USER_PROFILE)
            return story

        except Exception as e:
            logger.exception("describe_place failed")
            return f"Sorry, I couldn't describe the place: {e}"

        finally:
            if tmp_path and os.path.exists(tmp_path):
                with contextlib.suppress(Exception):
                    os.remove(tmp_path)

    # ---------- MAIN WS HANDLER ----------

    async def process_audio(self, websocket, client_id):
        """Process audio and video from the client using ADK."""
        # Store reference to client
        self.active_clients[client_id] = websocket

        # Create session for this client
        session = await self.session_service.create_session(
            app_name="multimodal_assistant",
            user_id=f"user_{client_id}",
            session_id=f"session_{client_id}",
        )

        # Create runner
        runner = Runner(
            app_name="multimodal_assistant",
            agent=self.agent,
            session_service=self.session_service,
        )

        # Create live request queue
        live_request_queue = LiveRequestQueue()

        # Create run config with audio settings
        run_config = RunConfig(
            streaming_mode=StreamingMode.BIDI,
            speech_config=types.SpeechConfig(
                voice_config=types.VoiceConfig(
                    prebuilt_voice_config=types.PrebuiltVoiceConfig(
                        voice_name=VOICE_NAME
                    )
                )
            ),
            response_modalities=["AUDIO"],
            output_audio_transcription=types.AudioTranscriptionConfig(),
            input_audio_transcription=types.AudioTranscriptionConfig(),
        )

        # Bounded queues for audio/video to avoid unbounded growth
        audio_queue = asyncio.Queue(maxsize=50)
        video_queue = asyncio.Queue(maxsize=5)

        client_alive = True  # guard to stop sending after browser disconnects

        async with asyncio.TaskGroup() as tg:

            # -------- Incoming WS messages --------
            async def handle_websocket_messages():
                nonlocal client_alive
                try:
                    async for message in websocket:
                        try:
                            data = json.loads(message)
                        except json.JSONDecodeError:
                            logger.error("Invalid JSON message received")
                            continue

                        msg_type = data.get("type")

                        if msg_type == "audio":
                            # Decode base64 audio data
                            try:
                                audio_bytes = base64.b64decode(data.get("data", ""))
                            except Exception as e:
                                logger.error(f"Audio b64 decode error: {e}")
                                continue
                            # Drop oldest if queue is full (keep realtime)
                            if audio_queue.full():
                                _ = audio_queue.get_nowait()
                                audio_queue.task_done()
                            await audio_queue.put(audio_bytes)

                        elif msg_type == "video":
                            try:
                                video_bytes = base64.b64decode(data.get("data", ""))
                            except Exception as e:
                                logger.error(f"Video b64 decode error: {e}")
                                continue
                            video_mode = data.get("mode", "webcam")
                            if video_queue.full():
                                _ = video_queue.get_nowait()
                                video_queue.task_done()
                            await video_queue.put({"data": video_bytes, "mode": video_mode})

                        elif msg_type == "end":
                            logger.info("Received end signal from client")

                        elif msg_type in ("text", "speak_text"):
                            txt = data.get("data", "") or ""
                            if msg_type == "speak_text":
                                txt = f"Read the following verbatim and do not add anything else: {txt}"
                            # Forward text to ADK
                            live_request_queue.send_realtime(types.Part(text=txt))
                            logger.info("Forwarded text to live_request_queue for narration")

                except (ConnectionClosed, ConnectionClosedError):
                    logger.info("Browser client closed the connection")
                except Exception as e:
                    logger.exception(f"MessageHandler error: {e}")
                finally:
                    client_alive = False
                    # Unblock workers so TaskGroup can exit cleanly
                    with contextlib.suppress(Exception):
                        await audio_queue.put(None)
                        await video_queue.put(None)

            # -------- Audio worker --------
            async def process_and_send_audio():
                while True:
                    data = await audio_queue.get()
                    try:
                        if data is None:  # sentinel
                            return
                        live_request_queue.send_realtime(
                            types.Blob(
                                data=data,
                                mime_type=f"audio/pcm;rate={SEND_SAMPLE_RATE}",
                            )
                        )
                    except Exception as e:
                        logger.exception(f"AudioProcessor error: {e}")
                        return
                    finally:
                        audio_queue.task_done()

            # -------- Video worker --------
            async def process_and_send_video():
                while True:
                    video_data = await video_queue.get()
                    try:
                        if video_data is None:  # sentinel
                            return
                        video_bytes = video_data.get("data")
                        video_mode = video_data.get("mode", "webcam")
                        logger.info(f"Processing video frame from {video_mode}")

                        # –û–±–Ω–æ–≤–ª—è–µ–º –±—É—Ñ–µ—Ä –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∫–∞–¥—Ä–∞ + —Ç–∞–π–º—à—Ç–∞–º–ø
                        if video_bytes:
                            with self._frame_lock:
                                self.latest_frame = video_bytes
                                self.latest_frame_ts = time.time()

                        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–¥—Ä –≤ ADK (–¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞/–º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏)
                        live_request_queue.send_realtime(
                            types.Blob(
                                data=video_bytes,
                                mime_type="image/jpeg",
                            )
                        )
                    except Exception as e:
                        logger.exception(f"VideoProcessor error: {e}")
                        return
                    finally:
                        video_queue.task_done()

            # -------- ADK responses --------
            async def receive_and_process_responses():
                input_texts = []
                output_texts = []
                current_session_id = None

                interrupted = False

                try:
                    async for event in runner.run_live(
                        session=session,
                        live_request_queue=live_request_queue,
                        run_config=run_config,
                    ):
                        event_str = str(event)

                        # Session resumption
                        if (
                            hasattr(event, "session_resumption_update")
                            and event.session_resumption_update
                        ):
                            update = event.session_resumption_update
                            if update.resumable and update.new_handle:
                                current_session_id = update.new_handle
                                logger.info(f"New SESSION: {current_session_id}")
                                if client_alive:
                                    with contextlib.suppress(Exception):
                                        await websocket.send(
                                            json.dumps(
                                                {"type": "session_id", "data": current_session_id}
                                            )
                                        )

                        # Content handling
                        if event.content and event.content.parts:
                            for part in event.content.parts:
                                # Audio chunks from model
                                if hasattr(part, "inline_data") and part.inline_data:
                                    b64_audio = base64.b64encode(part.inline_data.data).decode("utf-8")
                                    if client_alive:
                                        with contextlib.suppress(Exception):
                                            await websocket.send(
                                                json.dumps({"type": "audio", "data": b64_audio})
                                            )

                                # Text chunks
                                if hasattr(part, "text") and part.text:
                                    if hasattr(event.content, "role") and event.content.role == "user":
                                        # –ù–µ —ç—Ö–æ–∏–º –≤ –∫–ª–∏–µ–Ω—Ç; –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –Ω–∞–º–µ—Ä–µ–Ω–∏—è
                                        input_texts.append(part.text)
                                        # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                                        self._allow_describe_place = self._allow_from_user_text(part.text)
                                    else:
                                        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ partial, —á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å —Ñ–∏–Ω–∞–ª
                                        if "partial=True" in event_str:
                                            if client_alive:
                                                with contextlib.suppress(Exception):
                                                    await websocket.send(
                                                        json.dumps({"type": "text", "data": part.text})
                                                    )
                                            output_texts.append(part.text)

                        # Interruption
                        if event.interrupted and not interrupted:
                            logger.info("ü§ê INTERRUPTION DETECTED")
                            if client_alive:
                                with contextlib.suppress(Exception):
                                    await websocket.send(
                                        json.dumps(
                                            {"type": "interrupted", "data": "Response interrupted by user input"}
                                        )
                                    )
                            interrupted = True

                        # Turn complete
                        if event.turn_complete:
                            if not interrupted and client_alive:
                                with contextlib.suppress(Exception):
                                    await websocket.send(
                                        json.dumps({"type": "turn_complete", "session_id": current_session_id})
                                    )

                            # Logs (dedup)
                            if input_texts:
                                unique = list(dict.fromkeys(input_texts))
                                logger.info(f"Input transcription: {' '.join(unique)}")
                            if output_texts:
                                unique = list(dict.fromkeys(output_texts))
                                logger.info(f"Output transcription: {' '.join(unique)}")

                            # Reset per turn
                            input_texts = []
                            output_texts = []
                            interrupted = False
                            self._allow_describe_place = False  # —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–∞ —Ç—É–ª

                except (ConnectionClosedError, ConnectionClosed, TimeoutError) as e:
                    logger.error(f"Gemini live connection closed: {e}")
                    if client_alive:
                        with contextlib.suppress(Exception):
                            await websocket.send(json.dumps({"type": "error", "data": "model_connection_closed"}))
                except asyncio.CancelledError:
                    raise
                except Exception as e:
                    logger.exception(f"Unexpected error in ResponseHandler: {e}")
                    if client_alive:
                        with contextlib.suppress(Exception):
                            await websocket.send(json.dumps({"type": "error", "data": "server_error"}))
                finally:
                    # Make sure workers can exit if this task dies first
                    with contextlib.suppress(Exception):
                        await audio_queue.put(None)
                        await video_queue.put(None)

            # Start all tasks
            tg.create_task(handle_websocket_messages(), name="MessageHandler")
            tg.create_task(process_and_send_audio(), name="AudioProcessor")
            tg.create_task(process_and_send_video(), name="VideoProcessor")
            tg.create_task(receive_and_process_responses(), name="ResponseHandler")


async def main():
    """Main function to start the server"""
    server = MultimodalADKServer()
    await server.start()


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("Exiting application via KeyboardInterrupt...")
    except Exception as e:
        logger.error(f"Unhandled exception in main: {e}")
        import traceback
        traceback.print_exc()
